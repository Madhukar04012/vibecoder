"""
Project Builder - Creates real folders and files on disk
Takes the project structure dict and writes it to the filesystem.

S-class features:
- Quality validation before writing
- Automatic S-class template injection for missing essential files
- Detailed build report with quality score
- Safe file writing with encoding handling
"""

import os
import logging
from pathlib import Path
from typing import Dict, Any, Optional

logger = logging.getLogger(__name__)


def _path_to_nested(path: str, content: str) -> dict:
    """Convert 'auth/security.py' -> {'auth': {'security.py': content}}"""
    parts = path.replace("\\", "/").split("/")
    result = {parts[-1]: content}
    for part in reversed(parts[:-1]):
        result = {part: result}
    return result


def _deep_merge(base: dict, overlay: dict) -> dict:
    """Recursively merge overlay into base. Overlay wins on conflicts."""
    result = dict(base)
    for key, value in overlay.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            result[key] = _deep_merge(result[key], value)
        else:
            result[key] = value
    return result


def _flatten_structure(structure: dict, prefix: str = "") -> Dict[str, str]:
    """Flatten nested dict into {path: content} pairs."""
    flat = {}
    for name, content in structure.items():
        path = f"{prefix}/{name}" if prefix else name
        if isinstance(content, dict):
            flat.update(_flatten_structure(content, path))
        elif isinstance(content, str):
            flat[path] = content
    return flat


def _inject_essential_files(structure: dict, project_name: str) -> dict:
    """Inject essential S-class files that may be missing."""
    try:
        from backend.templates.sclass_templates import get_sclass_root_templates
        # Provide default tech stack for essential files
        tech_stack = {
            "backend": "FastAPI",
            "frontend": "React",
            "database": "PostgreSQL"
        }
        root_templates = get_sclass_root_templates(project_name, tech_stack)
    except ImportError:
        root_templates = {}
    
    inner = structure.get(project_name, structure)
    
    # Inject essential root files if missing
    essential_root = [".gitignore", "docker-compose.yml"]
    for fname in essential_root:
        if fname not in inner and fname in root_templates:
            inner[fname] = root_templates[fname]
    
    # Ensure README exists
    if "README.md" not in inner:
        inner["README.md"] = f"# {project_name}\n\nGenerated by VibeCoder — S-class quality.\n\n## Setup\n\n```bash\n# Install dependencies\nnpm install  # frontend\npip install -r requirements.txt  # backend\n\n# Start development\nnpm run dev  # frontend\nuvicorn main:app --reload  # backend\n```\n"
    
    # Ensure .github/workflows exists for CI
    if ".github" not in inner:
        inner[".github"] = {
            "workflows": {
                "ci.yml": root_templates.get(".github/workflows/ci.yml", 
                    "name: CI\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Build\n        run: echo 'Build step'\n")
            }
        }
    
    if project_name in structure:
        structure[project_name] = inner
    else:
        structure = inner
    
    return structure


def _validate_file_content(path: str, content: str) -> list:
    """Validate a single file for common issues. Returns list of warnings."""
    warnings = []
    
    if not content or not content.strip():
        warnings.append(f"EMPTY: {path}")
        return warnings
    
    # Check for placeholder content
    lower = content.lower()
    if len(content.strip()) < 20 and ("todo" in lower or "placeholder" in lower):
        warnings.append(f"PLACEHOLDER: {path} — content is just a placeholder")
    
    # Check for hardcoded secrets
    secret_patterns = ["sk-", "password123", "secret123", "changeme", "hardcoded"]
    for pattern in secret_patterns:
        if pattern in lower and ".env" not in path and "example" not in path:
            warnings.append(f"SECURITY: {path} — possible hardcoded secret ({pattern})")
    
    # Check TypeScript for 'any' type abuse
    if path.endswith((".ts", ".tsx")) and content.count(": any") > 3:
        warnings.append(f"QUALITY: {path} — excessive 'any' types ({content.count(': any')})")
    
    # Check for console.log in production code
    if path.endswith((".ts", ".tsx", ".js", ".jsx")) and "test" not in path.lower():
        console_count = content.count("console.log")
        if console_count > 2:
            warnings.append(f"QUALITY: {path} — {console_count} console.log statements")
    
    return warnings


def merge_agent_outputs(
    coder_output: dict,
    agent_outputs: Dict[str, Any],
        ) -> dict:
    """
    Merge auth, tester, deployer outputs into coder structure.
    Auth files go into backend/auth/, tests into tests/, deploy at root.
    """
    # Coder output: {project_name: {backend: {...}, frontend: {...}, ...}}
    if not coder_output:
        return {}

    project_name = list(coder_output.keys())[0] if coder_output else "my_project"
    structure = dict(coder_output)

    # Auth files: auth/security.py -> backend/auth/security.py
    auth = agent_outputs.get("auth", {})
    auth_files = auth.get("auth", {}).get("files", {}) or auth.get("files", {})
    for path, content in auth_files.items():
        nested = _path_to_nested(path, content)
        inner = structure.get(project_name, {})
        backend = inner.get("backend", {})
        backend = _deep_merge(backend, nested)
        inner["backend"] = backend
        structure[project_name] = inner

    # Test files: tests/conftest.py
    tester = agent_outputs.get("tester", {})
    test_files = tester.get("tests", {}).get("files", {}) or tester.get("files", {})
    for path, content in test_files.items():
        nested = _path_to_nested(path, content)
        inner = structure.get(project_name, {})
        inner = _deep_merge(inner, nested)
        structure[project_name] = inner

    # Deploy files: Dockerfile, docker-compose.yml at root
    deploy = agent_outputs.get("deployer", {}) or agent_outputs.get("deploy", {})
    deploy_data = deploy.get("deploy", deploy)
    deploy_files = deploy_data.get("files", {})
    for path, content in deploy_files.items():
        nested = _path_to_nested(path, content)
        inner = structure.get(project_name, {})
        inner = _deep_merge(inner, nested)
        structure[project_name] = inner

    # Inject essential S-class files
    structure = _inject_essential_files(structure, project_name)

    return structure


def build_project(structure: dict, output_dir: str = "./output") -> dict:
    """
    Takes a nested dict structure and creates real folders/files.
    
    Includes S-class quality features:
    - File content validation with warnings
    - Essential file injection
    - Detailed build report
    
    Args:
        structure: Nested dict where keys are folder/file names
                   and values are either dicts (folders) or strings (file content)
        output_dir: Base directory to create the project in
    
    Returns:
        dict with created paths, status, and quality report
    """
    created_files = []
    created_dirs = []
    warnings = []
    errors = []
    
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    
    def create_recursive(current_structure: dict, current_path: Path):
        for name, content in current_structure.items():
            item_path = current_path / name
            
            if isinstance(content, dict):
                # It's a folder
                item_path.mkdir(parents=True, exist_ok=True)
                created_dirs.append(str(item_path))
                create_recursive(content, item_path)
            elif isinstance(content, str):
                # It's a file — validate first
                rel_path = str(item_path.relative_to(output_path))
                file_warnings = _validate_file_content(rel_path, content)
                warnings.extend(file_warnings)
                
                try:
                    item_path.parent.mkdir(parents=True, exist_ok=True)
                    item_path.write_text(content, encoding='utf-8')
                    created_files.append(str(item_path))
                except Exception as e:
                    error_msg = f"Failed to write {item_path}: {e}"
                    logger.error(error_msg)
                    errors.append(error_msg)
            else:
                logger.warning(f"Skipping {name}: unexpected content type {type(content)}")
    
    create_recursive(structure, output_path)
    
    # Quality scoring
    quality_score = _calculate_build_quality(created_files, warnings, errors)
    
    return {
        "output_dir": str(output_path.absolute()),
        "created_dirs": created_dirs,
        "created_files": created_files,
        "total_dirs": len(created_dirs),
        "total_files": len(created_files),
        "quality": {
            "score": quality_score,
            "tier": "S" if quality_score >= 90 else "A" if quality_score >= 75 else "B" if quality_score >= 50 else "C",
            "warnings": warnings,
            "errors": errors,
            "warnings_count": len(warnings),
            "errors_count": len(errors),
        },
    }


def _calculate_build_quality(files: list, warnings: list, errors: list) -> int:
    """Calculate a quality score 0-100 for the build."""
    score = 100
    
    # Penalize for few files (S-class should have 25+)
    file_count = len(files)
    if file_count < 10:
        score -= 30
    elif file_count < 20:
        score -= 15
    elif file_count < 25:
        score -= 5
    
    # Penalize for warnings
    score -= min(len(warnings) * 3, 20)
    
    # Penalize for errors
    score -= min(len(errors) * 10, 30)
    
    # Check for essential files
    file_names = [os.path.basename(f) for f in files]
    file_basenames = set(file_names)
    
    essential_files = {
        "package.json", "tsconfig.json", "vite.config.ts",
        "tailwind.config.ts", ".gitignore", "README.md",
        "main.tsx", "App.tsx", "index.css",
    }
    
    found_essential = len(essential_files & file_basenames)
    if found_essential < len(essential_files):
        missing_ratio = 1 - (found_essential / len(essential_files))
        score -= int(missing_ratio * 15)
    
    return max(0, min(100, score))
